


\section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this study focused on the examination of python projects and 
This study aims to address the absence of software engineering knowledge in AI projects by developing a framework that prioritizes open science and improves the developer experience. 
% The methodology involved analyzing open source deep learning projects and reviewing literature on software engineering practices, modularity, separation of concerns, and open science in AI. The resulting convention is simple, effective, and applicable to a wide range of AI projects.


The framework has been designed with the aims of promoting modularity, separation of concerns, consistent naming conventions to improve the maintainability and reusability of code in mind. The methodology for developing this framework involved analyzing existing open-source deep learning projects, reviewing the literature on software engineering practices, and studying modularity, separation of concerns, and open science in AI. The resulting framework prioritizes the creation of independent modules that are standalone and reusable components, which can be used across different projects.
% The convention is designed to prioritize modularity, separation of concerns, with consistent naming conventions to promote maintainability and reusability of code. It places a high priority on creating independent modules that are standalone and reusable components, which can be used across different projects. 



To evaluate the framework, it was tested with a variety of open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Lightning, Tensorflow, Keras, Darts, and Huggingface. The framework was also tested in various use cases, particle swarm optimization, computer vision experiment with ransac, and weight analysis. 
% In some cases, only the "experiment" module was necessary.

A case study was conducted to evaluate the convention's effectiveness in practice. The official implementation of Big Transfer (BiT)  (\cite{transferlearning}) was refactored to conform to the convention. The resulting code was evaluated for adherence to the convention and overall quality, with findings presented in Appendix A.
% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.

% The convention was designed to be simple, effective, and widely applicable to a range of AI and ML projects. The convention prioritized modularity, separation of concerns, and consistent naming conventions to promote the maintainability and reusability of code. The convention also included four distinct modules, namely "models", "data", "trainers", and "experiments". The "models" and "data" modules were designed to be independent and modular, while the "trainers" module was dependent on both "models" and "data". The "experiments" module was designed to combine the other modules and facilitate experimentation with different combinations of models, data, and trainers.

% To evaluate the effectiveness of the convention, it was tested with various AI and ML frameworks including Jax, Flax, PyTorch, TensorFlow, Keras, DARTS, and Hugging Face. The convention was also evaluated by looking at various open-source AI and ML projects and comparing their structure and organization to the proposed convention.

% \section{Methodology}

% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.


% \section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this project focuses on the examination of software engineering practices in the context of Python and its machine learning frameworks. Many interdisciplinary researchers may lack the software engineering expertise necessary to manage their code bases to ensure correctness, understandability, extendability, and reusability (\cite{amershi2019software,scully-debt-ml,leakage-recrisis,accountabilityInAi}). To address these challenges, we investigated the application of software engineering principles of separation of concerns (SoC) and modular design in Python to AI projects. The goal of this study was to improve the reproducibility and reusability of python AI components through the adoption of best software engineering practices.

% \subsection{Software Engineering for Python AI Projects}
%  In the context of AI, the implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This decoupling has the potential to greatly enhance the reusability of code greatly, enabling easier experimentation with models and datasets.


% \subsection{A Different Approach to Deep Learning Framework}

% An alternative approach to the compatibility and re-usability issue in deep learning frameworks is to enforce principles of separation of concerns (SoC) and modularity in Python. 
% The implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This separation enhances the reusability of the code, making it easier to experiment with different models and datasets within the same framework. This approach has the advantage of limiting the learning overhead to the principles of software engineering, rather than requiring a transition to a unified deep learning framework.



% A limitation of this approach is that it requires manual translation of AI components, such as data loaders and models, into different frameworks when necessary. While this approach may require additional effort, it allows for greater flexibility and customizability in implementing deep learning models. Additionally, it promotes a deeper understanding of the underlying software engineering principles and their application in the field of AI.


