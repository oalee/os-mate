
\section{Background Information}


\subsection{Crisis of Reproducibility in AI}
The crisis of reproducibility in AI refers to the difficulty in reproducing the results of AI research (\cite{gundersen2018reproducible}). The lack of transparency in data collection and research has greatly contributed to the crisis of reproducibility in AI (\cite{gundersen2018reproducible,hutson2018artificial,leakage-recrisis}). Many AI models are developed close sourced using proprietary data and methods, making it difficult for others to replicate the research and understand the inner workings of the models (\cite{gundersen2018reproducible,accountabilityInAi}). Additionally, the lack of transparency in the research process can lead to issues such as unreliable or biased methods data, which can further undermine the credibility and reproducibility of the research, and it can decrease the trust in the field as the results of the research are not independently verifiable  (\cite{accountabilityInAi,leakage-recrisis,scully-debt-ml}). The pressure to publish results and the lack of incentives to share data and code can discourage researchers from making their work easily reproducible. (\cite{psychology-reproducibility-crisis, friesike2015open,kwon2021incentive, ali2017motivating,o2017evaluation})



\subsection{Open Science}

Open science is a research methodology that prioritizes transparency, collaboration, and reproducibility (\cite{nielsen2011reinventing}). The promotion of open science in the field of AI has garnered considerable attention in recent years (\cite{accountabilityInAi,gundersen2018reproducible,leakage-recrisis,scully-debt-ml,stodden-towardreprodicibleresearch,coro2020open,braun2018open,hicks2021open,burgelman2019open}). In the field of AI, open science practices can help to address concerns about biased or unreliable data, as well as provide a way for researchers to collaborate and build reproducible research and enhance accountability in AI (\cite{accountabilityInAi,stodden-towardreprodicibleresearch}).  Open science encourages researchers to share their knowledge, data, code, and detailed documentation of their methods (\cite{hutson2018artificial,accountabilityInAi}). 
Researchers can also use open-source frameworks and standard evaluation metrics (\cite{gundersen2018reproducible}) to facilitate reproducibility. Furthermore, the scientific community can encourage reproducibility by valuing it in the peer-review process (\cite{scully-debt-ml}), and by giving credit to researchers who share their data and code (\cite{scully-debt-ml,credit-datasharing,stodden-towardreprodicibleresearch}).




\subsection{Fair Comparison of Models in AI}

Data is a crucial factor in the success of deep learning models (\cite{lecun2015deep}). The quality, pre-processing, and augmentations applied to the data can significantly impact the model's ability to extract knowledge and make accurate predictions (\cite{shorten2019survey}). Therefore, it is essential for researchers to consistently use the same data split, pre-processing and augmentations when comparing models to ensure fair comparisons (\cite{caton2020fairness,mehrabi2021survey, leakage-recrisis}).


\subsection{The FAIR Guiding Principles for scientific data management and stewardship }
The FAIR Guiding Principles for scientific data management and stewardship were introduced in 2016 as a guideline for improving the findability, accessibility, interoperability, and reusability of digital assets, with a focus on machine-actionability to enable computational systems to find, access, interoperate, and reuse data with minimal human intervention \cite{wilkinson2016fair}. The principles have been endorsed by a diverse set of stakeholders, including academia, industry, funding agencies, and scholarly publishers. The principles emphasize the importance of metadata in making data and digital assets easy to find, with machine-readable metadata being a crucial component of the FAIRification process \cite{wilkinson2016fair}. In addition to findability, the principles also address the accessibility of data, including the need for authentication and authorization for accessing digital assets \cite{wilkinson2016fair}. Interoperability is another critical aspect of the principles, with data needing to be integrated with other data and interoperable with applications or workflows for analysis, storage, and processing \cite{wilkinson2016fair}. The ultimate goal of the FAIR principles is to optimize the reuse of data, and well-described metadata and data are essential for data replication and reuse in different settings \cite{wilkinson2016fair}. The FAIR principles refer to three types of entities, including data or any digital object, metadata, which is information about the digital object, and infrastructure \cite{wilkinson2016fair}.

\subsection{The Significance of Open Science for AI}

 
Open science represents a crucial component in the pursuit of responsible and trustworthy AI (\cite{floridi2019establishing,coro2020open,braun2018open,hicks2021open}). By prioritizing transparency and reproducibility, researchers in the field can advance its development in a safer and trustworthy manner (\cite{coro2020open,floridi2018ai4people,kocak2022transparency,stodden-towardreprodicibleresearch}).
Open science practices serve to mitigate the risks associated with closed-source AI and big data bias, which have raised significant concerns among stakeholders (\cite{batarseh2020data, o2017weapons}). Adoption of open science and open source AI can increase the fairness and impartiality of AI models (\cite{stodden-towardreprodicibleresearch,accountabilityInAi,gundersen2018reproducible}) and enhance the credibility and trustworthiness of their outputs among stakeholders and decision-makers (\cite{goodman2017european,hsiao2018vtaiwan,praprotnikevaluation}). % 

\subsection{Open Source}
Open source is a development methodology that emphasizes collaboration, transparency, and community involvement. It involves the sharing of software code and the ability to view and modify that code, as opposed to proprietary or closed-source software where the code is not available for viewing or modification. Open source has been a driving force behind many technological advancements, with the internet itself being built on open source software such as Linux..
In the field of artificial intelligence, open source development has also played a significant role. Many popular machine learning and deep learning frameworks and libraries, such as Torch, Keras, Hugging Face, and Jax, are open source, allowing for a wider range of use cases, contributions from the community, and access to cutting-edge research. The open-source nature of these frameworks also enables a more transparent and collaborative development process.


\subsection{Software Engineering}
Software engineering is a well-established discipline that encompasses the process of designing, developing, testing, and maintaining software systems with a focus on quality, reliability, and efficiency \cite{pressman2010software}. While the specific activities and methodologies involved in software engineering can vary depending on the type of software, the principles of good software engineering practices are generally applicable across all types of software (\cite{pressman2010software}), including those in the field of artificial intelligence (\cite{se4dl,wan2019does,martinez2022softwareAI,davis2011understandingmodularity}). The software engineering practices employed in the development of AI systems include, but are not limited to, testing, debugging, documentation, version control, and code review. Additionally, given the complex and evolving nature of AI systems, specific attention must be given to software requirements and their evolution over time (\cite{heyn2021requirement,belani2019requirements}). However, unlike traditional software engineering, the requirements of AI systems may not always be well-defined, and software engineering practices may need to be adapted to the rapidly changing needs of these systems (\cite{heyn2021requirement,belani2019requirements}). 


\subsubsection{Separation of Concerns}
 The separation of concerns (SoC) is a software engineering principle that suggests that different aspects of a system should be separated into distinct components, allowing for increased clarity, maintainability, and scalability of code (\cite{pressman2010software, de2002importance}). 
 In the context of AI, this principle can be applied by separating different concerns of a AI into reusable components. By adhering to SoC, researchers can improve the clarity of their code and reduce the risk of introducing bugs and errors (\cite{mo2016decoupling,mo2016decoupling,pressman2010software, de2002importance}).

\subsubsection{Modularity}
Modularity, or the practice of creating reusable components, is a fundamental aspect of software engineering (\cite{pressman2010software}). By breaking down complex systems into smaller, reusable components, researchers can improve the understandability and extendability of their code. Additionally, modular code is more easily testable and maintainable, leading to increased reproducibility and reliability of results (\cite{amershi2019software,pressman2010software}). 
\subsubsection{Modualirty in Python}
In Python, modular design can be achieved through the use of functions, modules, and libraries (\cite{sanner1999python}). 
A python module contains definitions, functions, classes, and variables (\cite{raschka2015python}). By convention, modules are stored in separate directories, and a directory containing one or more modules is called a package. The presence of \verb|__init__.py| file in a package directory indicates that it is a package, and all files in the directory are considered modules of that package. In other words, the \verb|__init__.py| file makes the directory it's in a Python package, and any code in that file is executed when the package is imported.



\subsection{Developer Experience}
The concept of developer experience (DX) is a multidimensional construct that refers to developers' perceptions of various aspects of the development process, including the usability and effectiveness of the tools, frameworks, and platforms used (\cite{fagerholm2012developer}). DX is a critical factor in software development as it has the potential to impact productivity, motivation, and satisfaction (\cite{fagerholm2012developer}).



\subsection{Decoupling Concerns in Writing AI Code}


Decoupling concerns, also known as SoC, is a crucial design principle in the field of artificial intelligence and machine learning (\cite{mo2016decoupling,qian2006decoupling, pressman2010software}. For instance, in a typical deep learning experiment, the trainer component is responsible for training the model. The trainer component can be designed to receive either a string representing the dataset/model names or the actual dataset/model objects, with the latter approach providing greater flexibility and customization. Another example of separation of concerns in AI is the data loading and augmentation process, which can be hardcoded into the data loading module or passed as an object to a function. Similarly, a deep learning model can be implemented as a monolithic block of code or as a series of modular components, such as the encoder, decoder, and attention mechanism. The latter approach allows for greater flexibility and customization of the model, as each component can be modified or replaced without affecting the other components.



\section{Related Work}

In recent years, there has been an increasing demand for project structure templates to provide guidance and organization to data science projects. This trend has been towards modularization and separation of concerns to make projects more manageable and easier to maintain. This has been exemplified by frameworks like Cookiecutter, which separates the codebase into four main concerns, and Towards Data Science, which provides a comprehensive structure for data science projects. 

\subsection{Coockiecutter}
Cookiecutter is a popular tool that helps in setting up project directory structures and boilerplate code for Python-based projects. It provides a predefined directory structure, which includes nootbooks, reports, figures, references, license, and others, to help developers with setting up a consistent project directory structure. In contrast to Yerbamate, Cookiecutter separates the src directory into four concerns and modules: data, models, notebooks, and src, while Yerbamate creates an arbitrary number of independent modules. The predefined structure of Cookiecutter helps with separating out the different aspects of a project, such as data, models, and code, into their own directories. This can help make a project more organized and easier to navigate. However, the modularity provided by Yerbamate allows for more flexibility in how a project is structured, as it allows for the creation of independent modules without being restricted to a predefined structure.




\subsection{Software Engineering Practices For AI}


O
There have been several efforts to establish best practices for software engineering in AI, including the "Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and Infrastructure" publication which emphasizes the importance of open science principles in the development of AI datasets and the documentation process for researcher collaboration (\cite{accountabilityInAi}). These efforts aim to establish a more standardized and transparent approach to AI development, ultimately leading to more trustworthy and reliable AI systems.
