


\section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this study focused on the examination of python projects and 

In 2022, the development of an AI experimentation framework\footnote{\url{https://github.com/ilex-paraguariensis/yerbamate}} began as a means of experimentation with PyTorch Lightning and Generative Adversarial Netowrks (\cite{goodfellow2020generative}) for a research project at Maastricht University. The framework was further developed as an open source project, and later improved during a research internship at UVA. As part of this development, I contributed in the design of the system, implemented various functionalities such as a JSON configuration format capable of defining an experiment with Jax, PyTorch and Keras\footnote{\url{https://github.com/ilex-paraguariensis/bombilla}}. However, it was later found to be still inflexible, prompting a need for a more generalized and flexible approach. The framework was subsequently forked to Yerbamate\footnote{\url{https://github.com/oalee/yerbamate}}, as an individual effort to address the problems of flexibility and create an open science-focused general framework.

% This study aimed to address the knowledge gap in software engineering for AI by developing a framework that prioritizes open science and improves the developer experience. 
% The methodology involved analyzing open source deep learning projects and reviewing literature on software engineering practices, modularity, separation of concerns, and open science in AI. The resulting convention is simple, effective, and applicable to a wide range of AI projects.


% The Yerbamate framework was initially developed in 2022 as part of a research project at Maastricht University, focusing on experimentation with PyTorch Lightning and GANs. Its development was continued during deep learning assignments at the same university. Subsequently, an internship at UVA was undertaken to further improve the framework. Originally limited to PyTorch Lightning and utilizing JSON for experiment specification, it was later generalized to support Keras and JAX, still using JSON as the experimentation format. However, the use of JSON was found to be inflexible. As a result, the Yerbamate framework was forked from its predecessor to create a more flexible and adaptable open science framework.


The framework has been designed with the aims of promoting open science, software engineering best practices of modularity, separation of concerns, and consistent naming conventions to improve the maintainability and reusability of code in mind. The methodology for developing this framework involved analyzing existing open-source AI projects, reviewing the literature on software engineering practices, and studying modularity, separation of concerns, and open science in AI. The resulting framework prioritizes the creation of independent modules that are standalone and reusable components, which can be used across different projects.
% The convention is designed to prioritize modularity, separation of concerns, with consistent naming conventions to promote maintainability and reusability of code. It places a high priority on creating independent modules that are standalone and reusable components, which can be used across different projects. 



To evaluate the framework, it was tested with a variety of open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Lightning, Tensorflow, Keras, Darts, and Huggingface. To further demonstrate the flexibility, the framework was tested in various use cases, particle swarm optimization (\cite{kennedy1995particle})\footnote{\url{https://github.com/oalee/particle-swarm-optimization-and-gradient-descent}}, and a computer vision experiment with RANSAC (\cite{lowe2004distinctive})\footnote{\url{https://github.com/oalee/image-stitching-ransac}}.
% In some cases, only the "experiment" module was necessary.

A case study was conducted to evaluate the framework's effectiveness in practice. The official implementation of Big Transfer (BiT)  (\cite{transferlearning}) was refactored to conform to modularity. The resulting code was evaluated for shareability, extendability and overall quality, with findings presented in Appendix A.
% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.


\subsection{Experiment Configuration}

In the field of artificial intelligence and machine learning, defining hyperparameters and experiments plays a crucial role in the development and optimization of models \cite{wu2019hyperparameter}. The choice of format for defining experiments and hyperparameters can greatly impact the efficiency and flexibility of the experimentation process. After evaluating various formats such as JSON and TOML, it has been determined that Python is the most suitable format for defining experiments in AI and ML python projects. Python provides a high level of expressiveness and versatility, allowing for easy modifications and adaptations of the experiment definition. In addition, Python offers a straightforward syntax for defining hyperparameters and allows for the integration of existing code and libraries. This greatly reduces the overhead associated with switching between different languages or systems, leading to a more streamlined and efficient experimentation process. Furthermore, the ability to use Python's powerful libraries and modules enhances the experimentation process by providing access to a vast range of tools and resources. This further enables the exploration of a wider range of hyperparameters and models, leading to a more comprehensive understanding of the problem at hand.

Additionally, by incorporating well-documented Python code, the readability of the configuration file is improved, making it more accessible to researchers and practitioners alike. Furthermore, this format is executable directly with Python, which makes it Turing complete. This property is particularly useful because it means that the format can include arbitrary computation and is capable of expressing any algorithm, enhancing its flexibility and power.


% The convention was designed to be simple, effective, and widely applicable to a range of AI and ML projects. The convention prioritized modularity, separation of concerns, and consistent naming conventions to promote the maintainability and reusability of code. The convention also included four distinct modules, namely "models", "data", "trainers", and "experiments". The "models" and "data" modules were designed to be independent and modular, while the "trainers" module was dependent on both "models" and "data". The "experiments" module was designed to combine the other modules and facilitate experimentation with different combinations of models, data, and trainers.

% To evaluate the effectiveness of the convention, it was tested with various AI and ML frameworks including Jax, Flax, PyTorch, TensorFlow, Keras, DARTS, and Hugging Face. The convention was also evaluated by looking at various open-source AI and ML projects and comparing their structure and organization to the proposed convention.

% \section{Methodology}

% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.


% \section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this project focuses on the examination of software engineering practices in the context of Python and its machine learning frameworks. Many interdisciplinary researchers may lack the software engineering expertise necessary to manage their code bases to ensure correctness, understandability, extendability, and reusability (\cite{amershi2019software,scully-debt-ml,leakage-recrisis,accountabilityInAi}). To address these challenges, we investigated the application of software engineering principles of separation of concerns (SoC) and modular design in Python to AI projects. The goal of this study was to improve the reproducibility and reusability of python AI components through the adoption of best software engineering practices.

% \subsection{Software Engineering for Python AI Projects}
%  In the context of AI, the implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This decoupling has the potential to greatly enhance the reusability of code greatly, enabling easier experimentation with models and datasets.


% \subsection{A Different Approach to Deep Learning Framework}

% An alternative approach to the compatibility and re-usability issue in deep learning frameworks is to enforce principles of separation of concerns (SoC) and modularity in Python. 
% The implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This separation enhances the reusability of the code, making it easier to experiment with different models and datasets within the same framework. This approach has the advantage of limiting the learning overhead to the principles of software engineering, rather than requiring a transition to a unified deep learning framework.



% A limitation of this approach is that it requires manual translation of AI components, such as data loaders and models, into different frameworks when necessary. While this approach may require additional effort, it allows for greater flexibility and customizability in implementing deep learning models. Additionally, it promotes a deeper understanding of the underlying software engineering principles and their application in the field of AI.


