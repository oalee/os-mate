


\section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this study focused on the examination of python projects and 

% In 2022, the development of an AI experimentation framework\footnote{\url{https://github.com/ilex-paraguariensis/yerbamate}} began as a means of experimentation with PyTorch Lightning and Generative Adversarial Netowrks (\cite{goodfellow2020generative}) for a research project at Maastricht University. The framework was further developed as an open source project, and later improved during a research internship at UVA. As part of this development, I contributed in the design of the system, implemented various functionalities such as a JSON configuration format capable of defining an experiment with Jax, PyTorch and Keras\footnote{\url{https://github.com/ilex-paraguariensis/bombilla}}. However, it was later found to be still inflexible, prompting a need for a more generalized and flexible approach. The framework was subsequently forked to Yerbamate\footnote{\url{https://github.com/oalee/yerbamate}}, as an individual effort to address the problems of flexibility and to create an open science-focused general framework.

% This study aimed to address the knowledge gap in software engineering for AI by developing a framework that prioritizes open science and improves the developer experience. 

This study aimed to address the knowledge gap in software engineering for AI by developing a framework that prioritizes open science and improves the developer experience. 

\subsection{Open Science}

The methodology of open science in this work encompasses the development of the open-source framework Yerbamate\footnote{\url{https://github.com/oalee/yerbamate}} and the creation of an open science report\footnote{ \url{https://github.com/oalee/os-yerbamate}} for Yerbamate. Both repositories' progress history is publicly available, and the repositories provide open access to contributions, QA, ideas, and discussions using GitHub's platforms to enhance open science and encourage collaboration. A Medium article titled "The Ultimate Deep Learning Project Structure: A Software Engineerâ€™s Guide into the Land of AI"\footnote{\url{https://medium.com/@alee.rmi/c383f234fd2f}} has been published to disseminate knowledge of software engineering in a more accessible manner, incorporating humor and memes with the aim of enhance learning (\cite{powell1985humour}). This tutorial provides a simple and easy-to-understand introduction to software engineering for AI, and explaining modularity and its application in the context AI. Detailed documentation of the API and usage can be found on our Github repository\footnote{\url{https://oalee.github.io/yerbamate}}, and we are continuously working to improve and release new updates for potential bugs and limitations of this work.


\subsection{Framework Design}
% This framework has been designed with the aims of promoting open science, software engineering best practices of modularity, separation of concerns, and consistent naming conventions to improve the maintainability and reusability of code in mind. 
The methodology for developing this framework involved analyzing existing open-source python AI projects, reviewing the literature on software engineering practices, and studying modularity, separation of concerns, and open science in AI. The resulting framework prioritizes the creation of independent modules that are standalone and reusable components, which can be used across different projects.

\subsubsection{Experiment Configuration}

Defining hyperparameters and experiments plays a crucial role in AI development and optimization \cite{wu2019hyperparameter}. After evaluating various formats, it was decided that Python is the most suitable format for defining experiments in AI python projects due to its expressiveness, versatility, and straightforward syntax. The integration of existing code and libraries in Python reduces overhead and enhances the experimentation process. Python's powerful libraries and modules enable the exploration of a wider range of hyperparameters and models, leading to a more comprehensive understanding of the problem at hand. The use of well-documented Python code improves the readability of the configuration file, making it more accessible. Additionally, the format is executable directly with Python, which makes it Turing complete, capable of expressing any algorithm, enhancing its flexibility and power.



% The methodology involved analyzing open source deep learning projects and reviewing literature on software engineering practices, modularity, separation of concerns, and open science in AI. The resulting convention is simple, effective, and applicable to a wide range of AI projects.


% The Yerbamate framework was initially developed in 2022 as part of a research project at Maastricht University, focusing on experimentation with PyTorch Lightning and GANs. Its development was continued during deep learning assignments at the same university. Subsequently, an internship at UVA was undertaken to further improve the framework. Originally limited to PyTorch Lightning and utilizing JSON for experiment specification, it was later generalized to support Keras and JAX, still using JSON as the experimentation format. However, the use of JSON was found to be inflexible. As a result, the Yerbamate framework was forked from its predecessor to create a more flexible and adaptable open science framework.


% This framework has been designed with the aims of promoting open science, software engineering best practices of modularity, separation of concerns, and consistent naming conventions to improve the maintainability and reusability of code in mind. The methodology for developing this framework involved analyzing existing open-source AI projects, reviewing the literature on software engineering practices, and studying modularity, separation of concerns, and open science in AI. The resulting framework prioritizes the creation of independent modules that are standalone and reusable components, which can be used across different projects.
% The convention is designed to prioritize modularity, separation of concerns, with consistent naming conventions to promote maintainability and reusability of code. It places a high priority on creating independent modules that are standalone and reusable components, which can be used across different projects. 



% To evaluate the framework, it was tested with a variety of open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Lightning, Tensorflow, Keras, Darts, and Huggingface. To further demonstrate the flexibility, the framework was tested in various use cases, particle swarm optimization (\cite{kennedy1995particle})\footnote{\url{https://github.com/oalee/particle-swarm-optimization-and-gradient-descent}}, and a computer vision experiment with RANSAC (\cite{lowe2004distinctive})\footnote{\url{https://github.com/oalee/image-stitching-ransac}}.
% % In some cases, only the "experiment" module was necessary.

% A case study was conducted to evaluate the framework's effectiveness in practice. The official implementation of Big Transfer (BiT)  (\cite{transferlearning}) was refactored to conform to modularity. The resulting code was evaluated for shareability, extendability and overall quality, with findings presented in Appendix A.
% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.

% \subsection{Software Engineering}



% The convention was designed to be simple, effective, and widely applicable to a range of AI and ML projects. The convention prioritized modularity, separation of concerns, and consistent naming conventions to promote the maintainability and reusability of code. The convention also included four distinct modules, namely "models", "data", "trainers", and "experiments". The "models" and "data" modules were designed to be independent and modular, while the "trainers" module was dependent on both "models" and "data". The "experiments" module was designed to combine the other modules and facilitate experimentation with different combinations of models, data, and trainers.

% To evaluate the effectiveness of the convention, it was tested with various AI and ML frameworks including Jax, Flax, PyTorch, TensorFlow, Keras, DARTS, and Hugging Face. The convention was also evaluated by looking at various open-source AI and ML projects and comparing their structure and organization to the proposed convention.

% \section{Methodology}

% This study was conducted to develop a software engineering convention for AI and ML projects that promotes open science practices. The development of the convention involved a review of existing literature on software engineering best practices and the identification of key principles that could be applied to AI and ML projects.


% \section{Methodology}

% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this project focuses on the examination of software engineering practices in the context of Python and its machine learning frameworks. Many interdisciplinary researchers may lack the software engineering expertise necessary to manage their code bases to ensure correctness, understandability, extendability, and reusability (\cite{amershi2019software,scully-debt-ml,leakage-recrisis,accountabilityInAi}). To address these challenges, we investigated the application of software engineering principles of separation of concerns (SoC) and modular design in Python to AI projects. The goal of this study was to improve the reproducibility and reusability of python AI components through the adoption of best software engineering practices.

% \subsection{Software Engineering for Python AI Projects}
%  In the context of AI, the implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This decoupling has the potential to greatly enhance the reusability of code greatly, enabling easier experimentation with models and datasets.


% \subsection{A Different Approach to Deep Learning Framework}

% An alternative approach to the compatibility and re-usability issue in deep learning frameworks is to enforce principles of separation of concerns (SoC) and modularity in Python. 
% The implementation of modularity and SoC principles results in the separation of models, data-related components, and trainers. 
% This approach facilitates the creation of a modular design, where the code is organized into distinct, reusable components (\cite{sanner1999python,pressman2010software}). This separation enhances the reusability of the code, making it easier to experiment with different models and datasets within the same framework. This approach has the advantage of limiting the learning overhead to the principles of software engineering, rather than requiring a transition to a unified deep learning framework.



% A limitation of this approach is that it requires manual translation of AI components, such as data loaders and models, into different frameworks when necessary. While this approach may require additional effort, it allows for greater flexibility and customizability in implementing deep learning models. Additionally, it promotes a deeper understanding of the underlying software engineering principles and their application in the field of AI.

\subsection{Evaluation}

The YerbamatÃ© framework was tested on various open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Pytorch\-Lightning, Tensorflow, Keras, and Huggingface, to evaluate its effectiveness. The framework's flexibility was demonstrated through various use cases, such as particle swarm optimization (\cite{kennedy1995particle}) and a computer vision experiment with RANSAC (\cite{lowe2004distinctive}). Furthermore, the framework's effectiveness was evaluated through a case study involving the refactoring of the official implementation of Big Transfer (BiT) to conform to modularity. Code samples, installable modules, examples, and the results of the case study are available in the Appendix.

% The framework was tested with a variety of open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Lightning, Tensorflow, Keras, Darts, and Huggingface, to evaluate its effectiveness. The framework was also tested in various use cases, including particle swarm optimization (\cite{kennedy1995particle}) and a computer vision experiment with RANSAC (\cite{lowe2004distinctive}) to demonstrate its flexibility. Furthermore, a case study was conducted by refactoring the official implementation of Big Transfer (BiT) to conform to modularity. Code samplese, installable modules, examples and the results are available at appendix

% \subsection{Evaluation}


% To evaluate the framework, it was tested with a variety of open-source AI projects across different frameworks and libraries, including Jax, Flax, Pytorch, Lightning, Tensorflow, Keras, Darts, and Huggingface. To further demonstrate the flexibility, the framework was tested in various use cases, particle swarm optimization (\cite{kennedy1995particle})\footnote{\url{https://github.com/oalee/particle-swarm-optimization-and-gradient-descent}}, and a computer vision experiment with RANSAC (\cite{lowe2004distinctive})\footnote{\url{https://github.com/oalee/image-stitching-ransac}}.
% % In some cases, only the "experiment" module was necessary.

% A case study was conducted to evaluate the framework's effectiveness in practice. The official implementation of Big Transfer (BiT)  (\cite{transferlearning}) was refactored to conform to modularity. The resulting code was evaluated for shareability, extendability and overall quality, with findings presented in Appendix A.