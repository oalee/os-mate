
\section{Motivation}


The reproducibility crisis in AI has led to an increasing focus on open science practices to improve the validity and reproduciblity of research (\cite{coro2020open,braun2018open,hicks2021open,paton2019open,kocak2022transparency,stodden-towardreprodicibleresearch}. However, the lack of software engineering conventions and knowledge, among researchers and practitioners often leads to poorly structured and documented AI projects, resulting in reproducibility issues, bugs, and invalidation of research. (\cite{leakage-recrisis,epskamp2019reproducibilitybug, seAIsurvey, martinez2022softwareAI,mainatiblity}).
 
% Despite the significant progress in AI in recent years, the lack of widely adopted standardized software engineering practice remains a significant challenge. The absence of software engineering skills for AI  has led to several issues, including the presence of bugs and invalidation of research, making maintenance difficult, and hindering the wider adoption of AI systems (\cite{leakage-recrisis,epskamp2019reproducibilitybug, seAIsurvey, martinez2022softwareAI,mainatiblity}).
% The absence of widely adopted software engineering principles in AI research has resulted in barriers to collaboration and the building upon previous research. Open source research projects typically create their command line tool or framework to experiment with different models and hyperparameters, which can lead to comprehensive options but often result in limitations. This re-implementation of hyperparameter selection and experiment execution leads to reinvention of the wheel and a potential learning curve.

The absence of widely adopted software engineering principles in AI research has resulted in barriers to collaboration and building upon previous research (\cite{accountabilityInAi}). Open-source AI research projects often create their own command-line tools or frameworks to experiment with different models and hyperparameters, which can result in comprehensive options but also limitations. This often leads to the reinvention of the wheel, as each project implements the same tasks slightly differently for their specific needs.
% , making it challenging to share and reuse code across projects. 
% Additionally, this can result in time-consuming and repetitive work, impeding progress in the field.


% This re-implementation of hyperparameter selection and experiment execution can be time-consuming and can impede the sharing of models and trainers between researchers. 
% Therefore, there is a need for a standardized software engineering convention and framework for AI research projects that promotes modularity, reproducibility, reusability, shareability, and code quality.

This heterogeneity in software engineering practices poses a significant obstacle to code reuse and collaboration among researchers. In some cases, AI codes are of low quality, resembling spaghetti code that is hard to maintain (\cite{seAIsurvey,martinez2022softwareAI,amershi2019software,mainatiblity,leakage-recrisis,gezici2022systematicsoftware}). In contrast, others exhibit a more modular design, which can enhance code quality and maintainability (\cite{seAIsurvey,martinez2022softwareAI,wan2019does}). Moreover, the problem arises when attempting to use another researcher's model, data augmentation, or a specific approach, as it requires learning a new framework for hyperparameter configuration and execution. The lack of standardized software engineering practices increases the difficulty of reproducing and building upon previous research.
% To address these issues, we present a software engineering convention of modularity that enhances maintainability, code quality, and enables the sharing of models, trainers, data loaders, and code components between researchers and practitioners.

% Our research suggests that establishing standard software engineering practices for AI  can enhance collaboration and sharing between researchers and practitioners. This will make it easier to replicate and build upon previous work, leading to faster innovation and progress in the field. By adopting good software engineering practices, AI  systems can become more reliable, maintainable, and scalable, enabling their widespread adoption and use.


% The widespread adoption of the Python programming language in AI programming has been noted in recent studies (\cite{mihajlovic2020use,raschka2020machine}). As such, this project focuses on the examination of software engineering practices in the context of Python and its machine learning frameworks. Many interdisciplinary researchers may lack the software engineering expertise necessary to manage their code bases to ensure correctness, understandability, extendability, and reusability (\cite{amershi2019software,scully-debt-ml,leakage-recrisis,accountabilityInAi}).
% To address these challenges, we investigated the application of software engineering principles of separation of concerns (SoC) and modular design in Python to AI projects. The goal of this study was to improve the reproducibility and reusability of python AI components through the adoption of best software engineering practices. Software engineering is the process of designing, developing, and maintaining software systems efficiently and reliably (\cite{pressman2010software}).
% In this internship, I explored software engineering practices that could help researchers share and collaborate AI code.
